| Level | Category | Item | Core Idea | When to Use | Pitfalls / Anti-Patterns | Metrics / Signals | Keywords |
|---|---|---|---|---|---|---|---|
| Answer | Architecture | RustHallows | Vertically integrated Rust stack for 10-40x perf via kernel bypass, μs-scheduling & formal isolation. | I/O-bound workloads (network, storage, analytics) needing extreme performance & safety. | High implementation complexity; not for CPU-bound tasks; requires specific hardware. | Tail latency (p99.9), throughput (IOPS/Gbps), CPU cycles per I/O. | rust, os, microkernel, kernel-bypass, zero-copy, high-performance |
| Answer | Geostrategic Tech | Project Nirbhik | A Rust-first, cross-platform OS for Macs & PCs, aiming for digital sovereignty for India. | To reduce dependency on foreign OSes and build a secure, sovereign digital infrastructure. | Huge undertaking; hardware compatibility is a major challenge; ecosystem building is difficult. | Percentage of government/critical systems migrated, size of developer community. | digital-sovereignty, india, rust-os, cross-platform, geopolitics |
| Pillar | Architecture (Nirbhik) | Virtualization-First OS | Run the OS on a hypervisor and target standardized virtual hardware (VirtIO) to bypass physical driver development. | To build a new OS without the massive cost of writing drivers for the entire PC hardware ecosystem. | Performance overhead from virtualization; dependency on host OS/hypervisor. | Performance vs bare-metal, number of supported host hypervisors. | virtualization, hypervisor, virtio, driver-abstraction, kvm, hyper-v |
| Pattern | Architecture (Nirbhik) | VirtIO Driver Model | Exclusively write drivers for the VirtIO specification, letting the hypervisor translate to physical hardware. | In a virtualization-first OS to achieve broad hardware compatibility with minimal driver code. | Limited to the performance and features supported by the VirtIO spec and the hypervisor's implementation. | Throughput of VirtIO devices (net, blk, etc.), feature parity with native drivers. | virtio, paravirtualization, drivers, hypervisor |
| Anti-Pattern | Strategy (Nirbhik) | The GPL Problem (for new OS) | Using drivers from the Linux kernel (e.g., via a shim layer) would likely force the new OS kernel to be licensed under the GPL. | N/A (It's a problem to be avoided). | Conflicts with commercialization strategies that require a more permissive license (e.g., MIT/Apache). | N/A | gpl, licensing, linux-drivers, commercialization, legal-risk |
| Pillar | Architecture | Capability Microkernel + Partitioning | Establish minimal, high-assurance TCB using capabilities for isolation & partitioning for determinism. | Systems requiring provable isolation and mixed-criticality workloads (safety + best-effort). | Capability management complexity; performance overhead if not implemented carefully. | TCB size, IPC round-trip time, context switch latency. | capability, microkernel, isolation, partitioning, seL4, arinc-653 |
| Pillar | Architecture | User-Space Fast Path | Remove the kernel entirely from the I/O data path, giving applications direct, secure, and mediated access to hardware queues. | I/O-heavy applications where kernel overhead (syscalls, copies) is a bottleneck. | Loss of mature kernel features (e.g., TSO); increased application complexity. | I/O throughput (IOPS/Gbps), latency reduction vs kernel path. | kernel-bypass, user-space, i/o, arrakis, ix, dpdk, spdk, osdi14 |
| Pillar | Architecture | μs-Scale Scheduling | Employ fine-grained, preemptive schedulers that can make decisions every ~5µs to manage CPU resources for µsecond-scale tail latency. | Latency-sensitive services requiring predictable low tail latency and high CPU efficiency. | Centralized schedulers can be a bottleneck at high load; complex to tune policies. | P99.9 latency, 5µs preemption quantum, 6.6x throughput gain (RocksDB). | scheduler, microsecond, low-latency, shinjuku, shenango, caladan, preemptive, tail-latency, nsdi19 |
| Pattern | Kernel & Isolation | Ministry of Magic | Capability-based microkernel core with per-object rights, guarded IPC, and deterministic paths for hot syscalls. | Core of the OS, managing fundamental system resources and enforcing security policies. | Balancing minimalism with providing sufficient features for a rich OS. | IPC latency, syscall overhead, TCB size. | microkernel, capability, ipc, sel4, theseus, sel4-whitepaper |
| Pattern | Kernel & Isolation | Horcrux Partitions | Time/space partitioning for deterministic multi-tenancy, with switchable best-effort mode. | Mixed-criticality systems needing hard real-time guarantees for safety domains. | Can lead to lower overall resource utilization; complexity in configuration. | Jitter, deadline miss rate, partition switch overhead. | partitioning, arinc-653, real-time, determinism, mixed-criticality, avionics, rtos |
| Pattern | Kernel & Isolation | Fidelius | A capability-scoped secrets service that supports hardware-backed enclaves for enhanced security. | For managing secrets and sensitive data within isolated hardware compartments. | Complexity of managing secrets across different hardware backends (SGX, TrustZone). | Time to access a secret, overhead of enclave operations. | secrets-management, enclave, sgx, trustzone, cheri, capability-scoped |
| Pattern | Kernel & Isolation | Azkaban | A process jailer that creates per-service 'cells' with a capability-gated syscall namespace and enables fast, forkless clones. | For sandboxing individual services and limiting their access to system resources. | Managing the complexity of capability-gated syscall namespaces for diverse applications. | Time to create a new jail/cell, overhead of jailed process. | sandbox, jailer, container, syscall-filter, forkless, per-service-cells |
| Pattern | Kernel & Isolation | Horcrux FCUs (Fault-Containment Units) | Partition system into units with explicit failure budgets; a crash severs only that unit's capability graph. | For building highly resilient systems where failures in one component cannot cascade. | Defining appropriate failure budgets; managing inter-Horcrux communication. | Mean time to recovery (MTTR) after a fault, fault propagation rate. | fault-containment, resilience, failure-budget, cheri, capability |
| Pattern | Scheduling | Time-Turner | A μs-scale preemptive scheduler hybridizing Shinjuku, Shenango, and Caladan models. | For mixing latency-critical (LC) and best-effort (BE) workloads with low tail latency. | Centralized scheduling can be a bottleneck at high load; complex policy tuning. | 6.6x throughput gain on RocksDB (Shinjuku), 88% lower tail latency (Shinjuku). | scheduler, shinjuku, shenango, caladan, preemptive, hybrid, low-latency |
| Pattern | Scheduling & Reliability | Time-Turner Snapshots | Kernel-native, sub-ms temporal checkpoints of a process for instant rollbacks and deterministic replay. | For debugging tail-latency outliers or replaying production issues for fuzzing. | High storage overhead for snapshots; performance cost of checkpointing. | Snapshot creation time, rollback time, storage size per snapshot. | checkpoint, rollback, replay, debugging, deterministic-replay, rr |
| Pattern | Networking & IPC | Floo Network | Userspace NIC dataplane with per-queue rings, zero-copy mbufs, and batched completions. | High-throughput, low-latency networking that bypasses the kernel stack. | Lacks mature kernel features (TSO/LRO) initially; driver complexity. | Packets-per-second (PPS), network throughput (Gbps), per-packet latency. | kernel-bypass, networking, dpdk, zero-copy, nic, DPDK-like-API, rust-safe-types |
| Pattern | Networking & IPC | Owl Post | Lock-free message queues (SPSC/MPSC) backed by cache-aligned ring buffers with priority lanes. | For high-performance, low-contention inter-core or inter-process communication. | Lock-free programming is complex and error-prone. | Messages per second, latency per message. | lock-free, spsc, mpsc, ring-buffer, ipc |
| Pattern | Networking & IPC | Portkey Graph | Treat services, rings, and queues as a DAG and map the graph edges to physical hardware queues to preserve cache locality. | For optimizing complex microservice communication paths to improve performance. | Graph analysis can be complex; static mapping may not adapt well to dynamic workloads. | Cache miss rate on critical path, end-to-end latency of service chains. | dag, locality, cache-locality, microservices, ipc, scheduler |
| Pattern | Storage & Memory | Gringotts | Userspace NVMe/ZNS storage stack with queue pairs and zoned log-structuring. | High-performance storage applications needing direct, low-latency access to NVMe devices. | Host is responsible for GC in ZNS; requires specific ZNS-aware applications. | IOPS, storage bandwidth (GB/s), tail latency. | kernel-bypass, storage, spdk, nvme, zns, dma |
| Pattern | Storage & Memory | Room of Requirement | A tiered memory manager (DRAM/HBM/NVRAM) with predictable allocation classes and optional ZNS-aware page cache bypass. | For systems with heterogeneous memory types that require optimized data placement. | Complexity of managing data across tiers; performance can suffer from poor placement decisions. | Data access latency across tiers, hit rate for faster tiers. | tiered-memory, hbm, nvram, memory-management, zns |
| Pattern | GPU & Accelerators | Nimbus 2000 | Direct-path I/O between storage/NIC and GPU memory, bypassing the CPU. | GPU-centric workloads (ML training, analytics) that are bottlenecked by data loading. | Requires specific PCIe topology and hardware support (e.g., GDS). | GPU data loading bandwidth (GB/s), CPU utilization during transfers. | gpudirect, rdma, dma, p2p, gpu, nvme |
| Pattern | Observability | Pensieve (Observability) | Pervasive, low-overhead tracing using eBPF-like programs native to the OS. | Always-on system monitoring, performance analysis, and feedback for adaptive scheduling. | Risk of high data volume; complexity of in-kernel query engine. | Tracepoint overhead, query latency on trace data. | observability, tracing, ebpf, profiling, telemetry |
| Pattern | Observability | Marauder's Map | An always-on, real-time flame/timeline UI for performance monitoring. | For visualizing detailed system metrics like queue depths, cache misses, and tail-latency heatmaps. | High data volume can make visualization difficult; potential UI overhead. | N/A | observability, visualization, flamegraph, heatmap, ui |
| Pattern | Observability & Tooling | Hermione | A build, verification, and assurance pipeline for producing high-assurance software artifacts. | For projects requiring reproducible builds, static analysis, and supply chain security (SBOMs, signing). | Can significantly increase build times and complexity. | Build reproducibility, static analysis findings, SBOM completeness. | build-pipeline, verification, assurance, sbom, sigstore, ferrocene, slsa |
| Pattern | Safety & Certification | Certification by Composition | Certify a minimal, high-assurance TCB, then use its proven isolation to run most of the system as untrusted components. | Complex systems where certifying the entire monolith is infeasible or too expensive. | Requires a very strong, formally verified isolation kernel; safety case must rigorously justify the composition; high verification burden. | Size of TCB, number of lines of code requiring certification. | certification, composition, safety, iso26262, do-178c, sel4, verification-burden |
| Pattern | Security | Hardware-Enforced Capabilities | Use hardware architecture (like CHERI) to enforce memory safety and compartmentalization at the ISA level. | Systems requiring the highest levels of security and mitigation against memory-based vulnerabilities. | Requires specialized hardware; can have performance overhead if not designed carefully. | Number of memory safety vulnerabilities mitigated, performance overhead vs non-CHERI. | security, cheri, morello, capability, hardware-security, memory-safety |
| Pattern | SDK & DevEx | Ergonomic Capability-based SDK | Provide high-level, safe Rust APIs that represent capabilities as traits to enforce security at compile time. | To enable application developers to build secure applications without deep expertise in capability systems. | Can be too restrictive if not designed well; may hide important details from the developer. | Time to build a secure 'hello world' app, number of unsafe blocks needed in typical apps. | sdk, devex, capability, rust, ergonomics, cap-std |
| Reference | Foundational Tech | seL4 | High-assurance microkernel with formal, machine-checked proof of isolation, confidentiality, and integrity, inspiring the capability model. | When provable security and isolation are paramount system requirements. | Steep learning curve; minimal by design, requiring significant user-space services. | N/A | sel4, microkernel, formal-verification, capability, l4-microkernel, high-assurance |
| Reference | Foundational Tech | DPDK / SPDK | Userspace kits for high-performance networking and storage, inspiring the kernel-bypass approach. | When maximum I/O performance is needed on commodity hardware. | Requires polling (burns CPU); applications must be written against their APIs. | N/A | dpdk, spdk, kernel-bypass, poll-mode-driver, pmd |
| Reference | Foundational Tech | Ferrocene | Qualified Rust compiler toolchain for safety-critical systems (ISO 26262, IEC 61508). | When building certified Rust applications for safety-critical environments. | Is a commercial product; may have licensing costs and restrictions. | N/A | ferrocene, rust, safety, certification, iso26262 |
