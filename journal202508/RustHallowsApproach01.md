# What can speed up our building in next 1 month?
``` text
We need to ideate
- how can we write Rust code for both no_std and std with worst free LLM help?
    - if architecture options are clear enough
    - if idiomatic pattern reference files are SOTA
    - if we can use TDD as the driving force
-  which app-specific-real-time-partitioned-kernel can offer a clear differentiation?
    - Data Ecosystem for aggregation
        - Kafka-inspired tool with Scala language : 10/10
        - Data Lake 
        - Spark PySpark
        - Pingora
    - UI : 2 / 10
    - Backend API : 6/10
    - Cache
    - OpenSearch or Elastic Search
    - Logging
    - Database : 
    - Load Balancers :
    - Streaming:
- what will create differentiation?
    - 
- Unclassified
    - Web Socket
    - WebRTC
    - GraphQL
    - protobuf
    - Storage
        - Block
        - File
        - S3
        - Object
        - RDBMS
   - Ideas for differentiation
      - Kafka
      - OpenSearch
      - Backend API

 
```


# Imagining delays via layers in a app response

## Website assuming backend is same
``` text
- Layer 1: OS
   - Layer 2 : Browser Engine
      - Layer 3 : HTML CSS JS

realtime-app-specific-partitioned-engine
RASPE - call it horcrux

normal browser < WASM runtime << realtime-app-specific-partitioned-engine

So, can we have the browser specific realtime-app-specific-partitioned-engine? Will it win significantly against the normal browser?
- Truly parallel browser like Servo
- Will Chrome be optimized more by realtime-app-specific-partitioned-engine?


```


## Backend API

## Database

## Cache

## OpenSearch

## Kafka

## Spark


